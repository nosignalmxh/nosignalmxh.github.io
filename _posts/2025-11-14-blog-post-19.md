---
title: 'Flow Matching梳理和虚拟细胞应用--组会整理'
date: 2025-11-14
permalink: /posts/2025/11/blog-post-19/
tags:
  - 机器学习
---

Flow Matching：从深度生成模型到虚拟细胞

> Creating noise from data is easy; creating data from noise is generative modeling.  
> —— Yang Song, 2020

这篇文章是我在组会讲 Flow Matching 主题的一次整理版本，既当作技术博客的记录，也希望能给之后再回顾这个方向的自己一个比较系统的“备忘录”。具体的ppt参见[Flow Matching_MA Xiaoheng](https://github.com/nosignalmxh/flow-matching-learning/blob/master/Flow%20Matching_MA%20Xiaoheng.pdf)。本文由GPT-5.1-High和GPT-5.1-Codex-High根据我的组会ppt和讲稿自动生成。

主要分三部分：

1. 从深度生成模型说起：从 GAN / VAE / Diffusion 到 Flow-based 模型  
2. Flow Matching 的原理与发展：如何“无积分”训练 CNF，以及与 Diffusion 的关系  
3. Flow Matching 在虚拟细胞（Virtual Cell）中的应用：为什么它在这个领域格外合适  

---

## 1. 深度生成模型：从噪声到数据

### 1.1 什么是生成模型？

抽象地看，生成模型就是构建一个模型分布 $p_\phi(x)$，去逼近真实数据分布 $p_{\text{data}}(x)$。

- 训练阶段：通过最大似然等方式，让 $p_\phi(x) \approx p_{\text{data}}(x)$  
- 采样阶段：从一个简单的先验分布（通常是高斯噪声）中采样 $z$，通过生成映射 $G$ 得到样本 $\hat x = G(z)$，希望它“看起来像来自真实数据分布”

直接在高维空间里对复杂分布建模是非常困难的，所以现代生成模型基本都采用一个通用范式：

- 从一个简单、已知的分布（如标准高斯）中采样  
- 通过一个可学习的变换，将“简单分布”逐步或一次性变成“复杂分布”

这就是那句经典的话的具体体现：

> 把数据变成噪声很容易，把噪声变成数据就是生成建模。

### 1.2 四大主流技术路线

目前主流的深度生成模型大致可以分为四条路线：

1. **GAN（Generative Adversarial Networks）**  
   - 思路：Generator 从噪声 $z$ 生成样本，Discriminator 判别真伪，两者对抗训练。  
   - 优点：能生成很清晰、细节丰富的样本。  
   - 典型问题：  
     - 训练不稳定（non-convergence）  
     - 模式崩塌（mode collapse）：只生成少数几种样本  
     - 容易出现梯度消失（vanishing gradients）  
     - 缺少显式的似然（likelihood），不适合“概率上严肃”地评估模型

2. **VAE（Variational Autoencoder）**  
   - 思路：用 encoder 把数据压缩到潜在高斯空间，再用 decoder 从潜在表示重建数据。  
   - 优点：  
     - 结构简单，训练稳定  
     - 有明确的概率模型和变分下界（ELBO）  
   - 缺点：  
     - 优化的是 ELBO 而不是精确似然  
     - 从噪声到数据“一步到位”，表达能力有限，生成结果常偏模糊  

3. **Diffusion Models（扩散模型）**  
   - 核心想法：把 VAE 一步的生成拆成很多个小步（multi-step refinement）。  
   - 前向过程：从真实数据 $x_0$ 出发，逐步加噪声，最后变成纯高斯噪声 $x_T$，这一步是“固定的”，不需要训练。  
   - 反向过程：训练一个网络，在每个时间步预测“需要去掉的噪声”，一步步把噪声雕刻回数据。  
   - 特点：  
     - 通过多步细化，生成质量极高  
     - 损失函数相对简单：预测噪声 $\epsilon$  
   - 局限：  
     - 需要很多采样步（几十到上百步），推理成本高  
     - 通常假设高斯先验 + 特定扩散路径，分布与路径都比较“硬编码”  
     - 经典形式下用 ELBO 相关技巧来近似似然，精确似然需要通过 PF-ODE 等更复杂的方式计算

4. **Flow-based Models：NF 与 CNF**  
   - **Normalizing Flows (NF)**：  
     - 利用可逆变换和雅可比行列式的 change-of-variables 公式：  
       $$
       \log p_X(x) = \log p_Z(f(x)) + \log \left|\det \frac{\partial f(x)}{\partial x}\right|
       $$  
     - 优点：**精确似然**，可以直接做 MLE。  
     - 局限：需要变换既可逆又易于计算 Jacobian，结构设计受限。  
   - **Continuous Normalizing Flows (CNF)**：  
     - 把离散的变换链变成时间连续的 ODE：  
      $$
      \frac{\mathrm{d} x_t}{\mathrm{d} t} = v_\theta(x_t, t)
      $$  
       背后对应 Fokker–Planck / continuity equation。  
     - 每一次 MLE 步都需要对 ODE 做一次积分（simulation-based），计算成本高，误差也受数值积分影响。  

Flow-based 模型给了我们一个非常优雅的视角：生成建模 = 在空间和时间上“推动”一个简单分布，沿某条路径变成复杂分布。但传统 NF / CNF 的训练普遍依赖数值积分，计算代价不容忽视——这也为 Flow Matching 的出现埋下伏笔。

---

## 2. Flow Matching：不用积分训练 Flow 的新范式

### 2.1 问题：CNF 为何如此“贵”？

在 CNF 里，我们有一条从 $t=0$ 到 $t=1$ 的连续时间流：

$$
\frac{\mathrm{d} x_t}{\mathrm{d} t} = v_\theta(x_t, t), \quad x_{t=0} \sim p_0, \quad x_{t=1} \sim p_1 \approx p_{\text{data}}
$$

为了用最大似然训练这个模型，我们需要知道：

- 在 $t=1$ 时，样本 $x_1$ 的 log-likelihood $\log p_1(x_1)$  
- 这需要沿着时间轨迹对 log-density 的变化做积分（利用连续版的 change-of-variables）

这意味着：**每一次参数更新都要在网络里嵌一个 ODE 计算图，做数值积分**。这就是典型的 simulation-based 训练，成本高且有数值误差。

### 2.2 Flow Matching 的核心想法

Flow Matching 的问题设定是：

> 能不能直接训练出一个“正确的速度场” $v_\theta(x, t)$，  
> 让它的解（integral curve）自动把 $p_0$ 变成 $p_1$，  
> 而在训练时根本不需要显式求解 ODE？

结合我 PPT 里的 “Training a CNF without Simulation” 那一页，可以把流程拆得更具体：

1. **构造 Bridging Distribution**  
   - 取时间 $t \sim \mathcal{U}(0,1)$，再从源分布 $x_0 \sim p_0$ 和目标分布 $x_1 \sim p_1$ 采样。  
   - 定义一条便于采样的桥接路径，例如 slide 上那条最常见的线性插值 + 噪声的形式：  
     $$
     x_t = \alpha(t) x_0 + (1-\alpha(t)) x_1 + \sigma(t)\,\epsilon,\quad \epsilon \sim \mathcal{N}(0, I)
     $$
     其中 $\alpha(t)$ 与 $\sigma(t)$ 的设计由我们控制，用来决定路径的“形状”和平滑程度。

2. **写出解析速度 $v^{*}(x_t,t)$**  
   - 因为 $x_t$ 是我们显式构造出来的随机变量，可以直接对它求导：  
     $$
     v^{*}(x_t, t) = \frac{\partial x_t}{\partial t} = \dot{\alpha}(t)\,x_0 - \dot{\alpha}(t)\,x_1 + \dot{\sigma}(t)\,\epsilon
     $$
   - 这一步是 Flow Matching 的关键：我们不用再对 log-density 做积分，而是直接得到“真”速度场的闭式表达（也可以视作 continuity equation 的显式解）。

3. **最小化速度匹配的 MSE**  
   - 训练时，只需最小化网络与解析速度之间的均方误差：  
     $$
     \mathcal{L}_{\text{FM}} = \mathbb{E}_{t, x_0, x_1, \epsilon}\Big[\big\|v_\theta(x_t, t) - v^{*}(x_t, t)\big\|_2^2\Big]
     $$
   - 这正是讲稿里那句 “我们直接把真速度当监督信号” 的含义。

4. **Simulation-free 训练 + Few-step 采样**  
   - 因为每次更新都只涉及一次前向构造和 MSE 回归，完全**不用积分**；  
   - 但推理阶段仍旧遵循 ODE 采样，只是由于我们提前设计了“更直”的路径，通常只需要 4～10 个 Euler 或 Heun 步就能收敛到 $p_1$。  

因为训练中我们是直接在不同时间点上“监督”速度本身，而不是通过积分后的 log-likelihood 来间接约束，所以：

- 训练过程不需要在每次迭代里反复求 ODE 积分  
- 因此被称为 **simulation-free** 的 CNF 训练方式  
- 但推理时还是要沿着 ODE 进行采样，不过由于路径可设计得很“直”，往往只需要少量步即可

### 2.3 Conditional Flow Matching：用条件场近似边缘场

这里的 “Conditional” 不是指“有标签的条件生成”，而是指**把难算的边缘速度场，换成一族更容易写解析式的条件速度场**。这一点在 PPT 的 “Flow Matching: Conditional FM（Intractable vs Tractable）” 那页里画得很清楚。

回到第 2.2 节，如果我们直接写 Flow Matching 的理想目标，其实是对**边缘速度场** $u_t(x)$ 做回归：

- 边缘场 $u_t(x)$ 是 continuity equation 的解，需要知道每个时间 $t$ 下的边缘分布 $p_t(x)$。  
- 直接从数据里估计 $u_t(x)$ 基本是不可行的，这就是 slide 左边 “Intractable” 的部分。

Conditional Flow Matching 的关键 trick 是：  
与其去估计一个难的边缘场，不如构造一族**条件场** $u_t(x \mid x_0, x_1)$，让它们在期望意义下等价于 $u_t(x)$。

具体做法可以这样理解：

1. **引入端点对 $(x_0, x_1)$**  
   - 从某个耦合分布里采样起点和终点，例如 $(x_0, x_1) \sim \pi(x_0, x_1)$。  
   - 在最简单的 I-CFM 里，$\pi$ 可以是独立采样的乘积分布 $p_0(x_0)p_1(x_1)$。

2. **定义条件桥接分布 $p_t(x \mid x_0, x_1)$**  
   - 就像 2.2 节那样，我们显式写一条连接 $x_0$ 和 $x_1$ 的路径，并加上适当噪声：  
     $$
     x_t \sim p_t(\cdot \mid x_0, x_1)
     $$
   - 对这条“条件路径”，我们可以推导出一个条件速度场 $u_t(x \mid x_0, x_1)$，并用闭式公式写出。

3. **用条件目标代替边缘目标**  
   - Conditional FM 的训练目标变成：  
     $$
     \mathcal{L}_{\text{CFM}} = \mathbb{E}_{t,\,x_0,\,x_1,\,x_t}\Big[\big\|v_\theta(x_t, t) - u_t(x_t \mid x_0, x_1)\big\|_2^2\Big],
     $$
     其中 $x_t \sim p_t(\cdot \mid x_0, x_1)$。  
   - 理论上可以证明：只要桥接分布设计得当，对所有条件场求期望之后，得到的就是我们真正想要的边缘场 $u_t(x)$。也就是说，CFM 只是把难求的边缘目标，换成了可计算的条件目标。

4. **I-CFM：更简单的条件耦合**  
   - PPT 上 “I-CFM + Euler Method” 那一页，就是在说一种特别实用的 CFM 实现：Independent Conditional Flow Matching。  
   - 核心是：  
     - $(x_0, x_1)$ 可以独立抽样，无需构造复杂耦合；  
     - 对于选好的桥接形式，条件速度 $u_t(x \mid x_0, x_1)$ 有非常简单的闭式形式；  
     - 采样时配合 Euler 等简单 ODE 求解器就能高效生成。  

从这个角度看，Conditional FM 是 Flow Matching 的一个**训练准则**：  
通过条件场，把理论上难以直接访问的边缘场“拆开”，变成一系列可以解析地写出来、也容易从数据中采样的子问题，最后再在期望意义下还原出我们想要的全局流。

### 2.4 路径设计与“直线”追求

把条件融进去只是第一步，第二步是 slide 上 “Path Straight?”、“Rectified FM”、“OT-CFM” 反复强调的主题：**路径形状直接决定采样效率和可解释性**。

- **Rectified Flow（整流流）**  
  - 如果我们把桥接路径直接设为线性插值 $x_t = (1-t)x_0 + t x_1$，那么解析速度就是常量 $x_1 - x_0$。  
  - 这意味着模型在训练阶段就学会沿着直线推进分布，采样时需要的 ODE 步数极少（4～8 步即可）。  
  - Stable Diffusion 3、FLUX.1 等工业系统就是沿着 “让路径变直” 的路线构建，相比传统 diffusion path，延迟更低、可控性更好。

- **OT-CFM 与 Metric Flow Matching**  
  - 在单细胞动力学中，我们往往关心“最省力”的演化轨迹。这正好与最优传输 (Optimal Transport) 的 geodesic 一致，所以 OT-CFM 会把路径限定在 OT 给出的最短路上。  
  - 如果数据本身位于复杂流形上，Metric Flow Matching 会把路径的“直线”改为流形上的测地线。这样虽然在欧式空间里看起来不是直线，但在真实度量下依然是最短路径。

- **路径不一定要“直”**  
  - 尽管直线能带来更快采样，但在某些生物学设定里，弯曲路径更符合真实过程（例如非平衡细胞命运转变）。  
  - Flow Matching 的优势在于：我们可以根据任务特性随意塑形。需要高效率时选择 rectified/straight path，需要可解释或生物先验时就选择 OT/metric path，甚至能在同一个框架里混合多段路径设计。

这部分总结了一个核心思想：**Flow Matching 不是只能“学一个路径”，而是提供了“设计路径”的自由度**。我们可以把条件信号、几何先验、效率要求全部编码进路径形状里，让模型在训练阶段就朝着期望的轨道前进。

---

## 3. Diffusion 与 Flow Matching：同一枚硬币的两面

从概率路径的角度看，Diffusion 与 Flow Matching 有着非常紧密的联系，可以用一组标准方程把两者统一到同一个框架下。

### 3.1 SDE、反向 SDE 与 PF-ODE

典型的连续时间扩散模型（如 variance-preserving SDE）写作：

$$
\mathrm{d}x_t = f(x_t, t)\,\mathrm{d}t + g(t)\,\mathrm{d}W_t,
$$

其中 $f$ 是 drift，$g$ 控制噪声强度，$W_t$ 是标准 Wiener 过程。前向过程从数据出发，在 $t=0$ 到 $t=1$ 或 $T$ 的区间内不断加噪，最终把 $x_0 \sim p_{\text{data}}$ 送到一个简单先验（通常是高斯）：

$$
x_T \sim p_T \approx \mathcal{N}(0, I).
$$

Song 等人在 ICLR 2021 中给出了对应的**反向时间 SDE**：

$$
\mathrm{d}x_t = \bigl[f(x_t, t) - g(t)^2 \nabla_x \log p_t(x_t)\bigr]\,\mathrm{d}t + g(t)\,\mathrm{d}\bar W_t,
$$

这里 $\nabla_x \log p_t(x_t)$ 就是时间 $t$ 的 score function，$\bar W_t$ 是反向时间 Brown 运动。只要我们学到了 score，就可以从先验 $p_T$ 出发，沿着这条反向 SDE 采样回数据分布。

更关键的是，同一套边缘分布 $p_t(x)$ 还对应一个**概率流 ODE（Probability Flow ODE，PF-ODE）**：

$$
\frac{\mathrm{d} x_t}{\mathrm{d} t}
 = f(x_t, t) - \frac{1}{2} g(t)^2 \nabla_x \log p_t(x_t).
$$

这条 ODE 没有随机噪声，但它在每个时间 $t$ 的边缘分布与原始的 SDE 完全一致。这正是 PPT 中那句 “Different Path, Same Marginal Distribution” 的数学形式：  

- 前向 SDE（加噪）、反向 SDE（去噪）、PF-ODE（确定性流）走的是三条不同路径；  
- 但它们在每个时间 $t$ 上共享同一个 $p_t(x)$。

### 3.2 训练视角：Diffusion = Flow Matching 特例

结合第 2 章的 Flow Matching 视角，可以把扩散模型看成一个**特殊路径 + 高斯源分布**下的 Flow Matching：

1. **源分布与路径固定**  
   - 源分布 $p_0$ 选为标准高斯 $\mathcal{N}(0,I)$。  
   - 概率路径 $p_t(x)$ 由前向 SDE 的 Green 函数唯一确定，相当于在 Flow Matching 里选择了“扩散路径”。

2. **训练：噪声预测损失等价于速度回归**  
   - 经典 DDPM/Score-based 模型的训练损失是：
     $$
     \mathcal{L}_{\text{diff}} = 
     \mathbb{E}_{x_0,\,t,\,\epsilon}\Big[\big\|
     \epsilon_\theta(x_t, t) - \epsilon
     \big\|_2^2\Big],
     $$
     其中 $x_t = \alpha(t) x_0 + \sigma(t)\epsilon$。  
   - 而 PF-ODE 的速度场可以写成 score 的线性变换：  
     $$
     v_{\text{PF}}(x_t, t)
     = f(x_t, t) - \tfrac{1}{2} g(t)^2 \nabla_x \log p_t(x_t).
     $$
   - 当我们训练一个网络去拟合 $\epsilon$ 或 score $\nabla_x \log p_t(x_t)$ 时，本质上就是在间接拟合 PF-ODE 的速度场 $v_{\text{PF}}$，因此也可以视为一种特殊的 Flow Matching。

3. **采样：Diffusion vs Flow Matching**  
   - 扩散模型采样时可选：  
     - 沿反向 SDE 走随机路径；  
     - 沿 PF-ODE 走确定性路径（包括 DDIM、DPM-Solver 等加速器都可看作对 ODE 的数值近似）。  
   - Flow Matching 直接从 PF-ODE 的视角出发，在训练中用 CFM/I-CFM 等准则学习速度场，在路径设计上不再受“扩散路径 + 高斯源”的限制，可以：  
     - 换成别的先验（如 ZINB）；  
     - 换成更“直”的路径（Rectified Flow）；  
     - 或在流形/OT 度量下设计更贴近结构的路径。

用一句话概括本节：  
**Diffusion 模型可以看作是在“高斯先验 + 扩散路径”这一特定设定下，对 PF-ODE 速度场的一种 Flow Matching；而 Flow Matching 则把这种思想推广到了任意可设计的路径和源分布上。**

---

## 4. Flow Matching 的“今生”：大模型与工业应用

Flow Matching 不只是理论上“更优雅”的生成框架，它正在快速走向工业主流。

### 4.1 成本—延迟—质量三角中的优势

在大型文生图、编辑类应用中，Flow Matching 的几个特点非常符合实际需求：

- **较少的采样步数**：  
  - 路径更直，适合用 few-step ODE 进行采样。  
  - 与使用 DDIM、DPM-Solver 等加速采样的 Diffusion 相比，各自从不同方向在压缩步数。  

- **精确似然 + 可控性**：  
  - 通过 CNF 视角，可以获得精确的 log-likelihood，方便评估与对齐。  

- **路径与先验可定制**：  
  - 在对齐、多轮编辑、保持身份一致性（identity consistency）等任务中，路径的可设计性非常有用。  

典型代表：

- **Stable Diffusion 3**  
  - 使用基于 Rectified Flow 的架构 + MMDiT 等组件。  
  - 实际效果表现为：更强的文本一致性、更稳定的布局、更低的推理成本。  

- **FLUX.1 / Rectified Flow Transformer**  
  - 把生成和编辑统一在同一流的框架之下，支持低延迟、多轮交互式编辑。  

这些系统的经验大致指向一个共识：  
> 在成本—延迟—质量的三角关系下，Flow Matching 提供了一个非常有竞争力的折中方案。

---

## 5. Flow Matching 在虚拟细胞中的应用

接下来进入本文最“个人兴趣”的部分：**为什么 Flow Matching 在虚拟细胞（Virtual Cell）领域特别适合？**

虚拟细胞领域涉及的任务很多，比如：

- 空间转录组（spatial transcriptomics）与形态学分析  
- 单细胞动力学与命运推断（cell dynamics & fate）  
- 扰动组学与药物反应预测（perturbation response）  

这些任务有几个共性：

1. 数据往往 **昂贵且稀缺（data-constrained）**  
2. 很多问题本质上是 **“分布到分布”的映射**，而不仅仅是“点到点”的预测  
3. 生物学过程常常由各种 **微分方程** 描述，包含复杂的动力学与非平衡现象  

Flow Matching 在这里几乎是一个“天然选手”。

### 5.1 Data-constrained 场景：Diffusion / FM 优于 AR

CMU 的一篇工作指出，在**数据受限（data-constrained）**的设置下：

- 在相同计算预算下，**Diffusion 模型往往优于自回归（AR）模型**  
- 在更高的 compute 下，Diffusion 的 loss 甚至会继续下降并最终超越 AR  

而在大模型场景（语言模型）中，我们更看重 compute-constrained 的 regime，这时 AR（例如 Transformer 做 next-token prediction）更划算；但在虚拟细胞领域：

- 单细胞、多组学数据获取成本极高，属于典型的数据稀缺场景  
- 计算资源相对来说更容易扩展一些  

因此，从理论和实验上都可以预期：**在 Virtual Cell 领域，Diffusion / Flow Matching 这类“更数据高效”的生成范式具有优势**。  
又因为 Diffusion 可以看作 Flow Matching 的一个特例，所以 Flow Matching 作为更一般的框架，天然适配这个领域。

### 5.2 Spatial & Morphology：灵活先验的优势（STFlow）

在空间转录组（spatial transcriptomics）和形态学分析中，一个典型任务是：

- 用低成本的 HE 图像去预测高成本的 ST 数据  
- ST 数据具有很多 **零膨胀（zero-inflation）** 的特点，即大量为 0 的计数数据  

**STFlow**（Liu T. et al., ICML 2025）中一个非常关键的设计是：

- 利用 Flow Matching 的“**先验分布可选择**”优势  
- 不再使用简单的高斯先验，而是采用更适合计数且多零的 **ZINB（Zero-Inflated Negative Binomial）分布** 作为源分布  

实验结果表明：

- 使用 ZINB 这类针对数据特性的先验，比用高斯先验的 Flow 模型效果显著更好  
- 这正是 Flow Matching 相比 Diffusion 的一大独特优势：  
  - Diffusion 通常固定在高斯先验 + 加噪路径  
  - Flow Matching 可以根据生物数据分布，自由地设计源分布

### 5.3 Cell Dynamics & Fate：从快照到连续轨迹

单细胞动力学建模可能是 Flow Matching 与虚拟细胞结合最紧密的应用方向之一。

背景：

- scRNA-seq 是破坏性的，一旦测序细胞就死亡，无法追踪“同一个细胞”随时间的轨迹  
- 实验上我们只能在不同时间点抽样不同细胞，得到一系列“离散快照”  
- 任务：从这些快照中重建细胞状态随时间的连续演化轨迹 —— **single-cell trajectory inference**

这个问题有几个关键特征：

- 我们要建模的是 **“分布到分布”的演化**，而不是“单点到单点”的映射  
- 背后自然可以用一个连续时间的流（ODE / CNF）来刻画  

因此，CNF / Flow Matching 几乎是天然适配的工具。

典型工作与发展：

- **TrajectoryNet**  
  - 最早将 CNF 引入到细胞动力学建模中，用模拟-based 的方式学习时间连续的演化流。  

- **OT-CFM**（Alexander Tong 等）  
  - 将 Flow Matching 和最优传输结合起来，成为 cell dynamics 领域中的一个标杆方法。  
  - 很多后续的 Flow Matching 工作都会在 single-cell dynamics 上做实验。  

- **Metric Flow Matching**（K. Kapusniak et al., NeurIPS 2024）  
  - 观察：单细胞数据往往位于高维空间中的某个低维流形上，在欧式空间里“走直线”不一定是最快路径。  
  - 类比：人在地球表面行走，最快路径是沿球面的测地线，而不是穿过地球内部的直线。  
  - Metric Flow Matching 在更符合数据流形的度量空间上设计路径，使得学到的细胞轨迹更符合真实结构。  

- **Unbalanced Flow Matching**（Wang D. 等，Peng D. 等）  
  - 标准的 continuity equation 假设“质量守恒”：分布之间变化只是重排，不增不减。  
  - 但在细胞动力学中，细胞会增殖（proliferation）与凋亡（death），系统是**非平衡**的。  
  - Unbalanced FM 在连续性方程中引入额外项 $g_t$ 来描述质量增减。  
  - 早期方法多为 simulation-based，而近期有工作受 Flow Matching 启发，尝试在这类更复杂的方程上也做 simulation-free 训练，大幅提升效率，同时保持与 simulation-based 方法接近的建模效果。  

总结来说：

- **CNF / Flow Matching 提供了从分布到分布、从快照到连续轨迹的自然数学框架**  
- 通过路径设计与度量设计的灵活性，可以逐步融入更多生物学结构假设（如流形、非平衡动力学等）

### 5.4 Perturbation Response：CellFlow 等

在扰动组学和药物反应预测中，一个核心问题是：

> 给定某个细胞在特定实验条件（药物、剂量、基因编辑等）下的转录组响应，  
> 预测在未做过的条件组合下，细胞会怎样响应？

现实中：

- 条件空间巨大（药物 × 剂量 × 组合 × 时间点……），完全实验测一遍几乎不可能  
- 我们希望用模型“外推”到未观测过的条件  

**CellFlow**（Theis Lab, bioRxiv 2025）等工作用 Flow Matching 来建模这个问题：

- 条件（实验设置）通过一个神经网络编码成条件向量  
- Flow Matching 学习从“源条件下的分布”到“目标条件下的分布”的变换  
- 这个设定中，Flow Matching 处理的是 **带条件的分布到分布映射**，比简单的点预测更符合任务本质  

这也是 Flow Matching 的另一项擅长场景：  
- 不只是“从噪声到目标分布”，而是“从一个有意义的分布到另一个有意义的分布”，中间的整个动态过程都可以被建模和解释。

---

## 6. 为什么说 Flow Matching 特别适合虚拟细胞？

综合上面的讨论，可以把 Flow Matching 在 Virtual Cell 中的优势总结为几个点：

1. **数据受限场景的性能优势**  
   - 理论与实验支持：在 data-constrained 设置下，Diffusion / Flow Matching 类模型往往优于 AR 模型。  
   - 单细胞和多组学数据获取昂贵，因此属于典型的数据受限领域。  

2. **先验选择灵活，能匹配生物数据分布**  
   - 可以选用非高斯先验，如 ZINB，更符合计数型转录组数据的统计特性。  
   - 比如 STFlow 中的 ZINB 源分布就显著优于高斯源分布。  

3. **天然支持“分布到分布”的建模**  
   - 很多虚拟细胞任务（cell dynamics、perturbation response 等）本质上是从一个细胞群体分布到另一个分布。  
   - Flow Matching 把这种变换作为一条连续时间流来建模，比点到点的回归更自然。  

4. **可解释的动态轨迹**  
   - 通过 ODE / CNF 的视角，可以看到完整的演化轨迹，而不仅仅是起点和终点。  
   - 这与很多生物问题中“重建细胞命运”与“理解逐步变化”的需求高度契合。  

5. **路径设计高度灵活**  
   - 可以选择直线路径、扩散路径，也可以在考虑流形结构的度量下设计路径（如 Metric Flow Matching）。  
   - 生物数据常常存在复杂的流形结构，灵活路径有助于更准确的建模。  

6. **与微分方程建模天然兼容**  
   - 很多生物过程本来就是用各种 ODE / SDE / PDE 来描述的。  
   - Flow Matching / CNF 提供了一个统一的“神经微分方程”视角：  
     - 对简单 ODE 可以直接 simulation-free 训练  
     - 对更复杂、非平衡的动力学，可以借鉴 Flow Matching 思想，逐步摆脱昂贵的模拟步骤  

7. **实践上效率与精确性兼备**  
   - Training 端：simulation-free，效率高  
   - Sampling 端：few-step ODE 可以获得高质量样本  
   - 在需要精确 likelihood 的场景（模型选择、置信评估等）中，也可以通过 CNF 视角获得精确似然

---

## 7. 小结与展望

如果用“前世今生”来概括 Flow Matching 的位置：

- **前世**：  
  - 起源于 Normalizing Flows / CNF，对 change-of-variables 和连续时间流的继承  
  - 与 Diffusion 在概率路径与 PF-ODE 层面的深度联系  

- **今生**：  
  - 在文生图、大模型编辑等工业场景中，借助 Rectified Flow、OT-CFM 等变体，成为兼顾成本、延迟与质量的重要路线  
  - 在虚拟细胞领域，凭借对分布到分布建模、流形结构、非平衡动力学的良好适配，逐渐成为一条非常有潜力的主线  

对我个人而言，Flow Matching 最吸引人的一点，是它把“生成模型”和“动力系统”这两条线真正结合起来：  
既能做很实用的高质量生成，又有一套很干净的数学结构，可以容纳各种生物学先验和动力学方程。

未来如果继续在虚拟细胞方向做工作，Flow Matching 大概率会一直是核心工具之一：  
- 一方面可以继续探索更贴近生物机制的路径与度量设计；  
- 另一方面，可以把更多复杂的微分方程（尤其是非平衡、含源汇项的系统）纳入 Flow Matching 式的高效训练框架中。

这篇文章就先整理到这里，算是对组会内容的一次系统“写档备份”。如果之后做了新的 Flow Matching 或 Virtual Cell 相关工作，再在这条线上继续更新。
